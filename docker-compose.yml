services:
  label-studio:
    container_name: label-studio
    image: heartexlabs/label-studio:latest
    ports:
      - 8080:8080
    environment:
      - LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true
      - LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/label-studio/data

      # - CSRF_TRUSTED_ORIGINS=https://college-clock-travel-administered.trycloudflare.com
      # - LABEL_STUDIO_HOST=https://college-clock-travel-administered.trycloudflare.com
    volumes:
      - ./data/ls_data:/label-studio/data
      - ./data/ls_data/source_storage:/label-studio/data/source_storage
      - ./data/ls_data/target_storage:/label-studio/data/target_storage
    stdin_open: true
    tty: true
 
  # -------------------------------------------------------
  # 1. The API Server (Handles Predict & Enqueues Training)
  # -------------------------------------------------------
  ml-backend:
    container_name: ml-backend-fasterrcnn
    build: 
      context: .
      dockerfile: ls_ml_backend/fasterrcnn_mobilenet_fpn/Dockerfile
      args:
        TEST_ENV: ${TEST_ENV}
    environment:
      - LOG_LEVEL=DEBUG
      - WORKERS=1
      - THREADS=8
      - MODEL_DIR=/data/model
      - LABEL_STUDIO_URL=${LABEL_STUDIO_URL}
      - LABEL_STUDIO_API_KEY=${LABEL_STUDIO_API_KEY}
      - NVIDIA_VISIBLE_DEVICES=all
      # Redis Config
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    gpus: all

    ports:
      - "9000:9000"
    volumes:
      - ./data/server:/data/server
      - ./data/ml-backend/fasterrcnn:/data/model/fasterrcnn
      - ./data/ls_data:/data/ls_data:ro
      - ./ls_ml_backend/fasterrcnn_mobilenet_fpn/model.py:/app/model.py
      - ./exp:/data/model/exp
    depends_on:
      - label-studio
      - redis
    
  # -------------------------------------------------------
  # 2. The Worker (Picks up Training jobs from Queue)
  # -------------------------------------------------------
  ml-backend-worker:
    container_name: ml-backend-worker
    build: 
      context: .
      dockerfile: ls_ml_backend/fasterrcnn_mobilenet_fpn/Dockerfile
      args:
        TEST_ENV: ${TEST_ENV}
    # Command to start the RQ worker listening on 'default' queue
    command: rq worker default --url redis://redis:6379
    environment:
      - LOG_LEVEL=DEBUG
      - MODEL_DIR=/data/model
      - LABEL_STUDIO_URL=${LABEL_STUDIO_URL}
      - LABEL_STUDIO_API_KEY=${LABEL_STUDIO_API_KEY}
      - NVIDIA_VISIBLE_DEVICES=all
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    gpus: all
    volumes:
      # MUST match server volumes exactly so it can write the model file
      - ./data/server:/data/server
      - ./data/ml-backend/fasterrcnn:/data/model/fasterrcnn
      - ./data/ls_data:/data/ls_data:ro
      - ./ls_ml_backend/fasterrcnn_mobilenet_fpn/model.py:/app/model.py
      - ./exp:/data/model/exp
    depends_on:
      - label-studio
      - redis
  
  # -------------------------------------------------------
  # 3. Redis Message Broker
  # -------------------------------------------------------
  redis:
    image: redis:alpine
    container_name: redis
    ports:
      - "6379:6379"
    
  ui-app:
    container_name: ui-app
    build: 
      context: .
      dockerfile: app/Dockerfile
    ports:
      - "5000:5000"
    volumes:
      # - ./app/app.py:/app/app.py
      - ./data/ls_data/source_storage/1:/app/data/ls_data/source_storage/1
    environment:
      - LABEL_STUDIO_URL=${LABEL_STUDIO_URL}
      - LABEL_STUDIO_API_KEY=${LABEL_STUDIO_API_KEY}
      - NVIDIA_VISIBLE_DEVICES=all
    gpus: all
    depends_on:
      - label-studio

  reverse-proxy:
    image: nginx:latest
    container_name: reverse-proxy
    ports:
    - "0.0.0.0:80:80"
    - "0.0.0.0:443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - ui-app
      - ml-backend
      - label-studio
